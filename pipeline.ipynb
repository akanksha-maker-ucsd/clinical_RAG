{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinical_RAG.modularized import Model\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Together API key \n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model system components \n",
    "# Data:       Loads initial patient database from file + preprocesses by chunking notes \n",
    "# Embedder:   Loads embedding model + can embed data \n",
    "# Storage:    Populates vector databases w/ patient data + can query indices \n",
    "# Generator:  Loads LLM model + can generate responses (untested!)\n",
    "\n",
    "data_path = \"discharge_notes_40_patients.csv\"\n",
    "embed_model = \"ClinicalBERT\"\n",
    "llm_model = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "api_key = os.environ[\"TOGETHER_API_KEY\"]\n",
    "\n",
    "model = Model(data_path, embed_model, api_key, llm_model)                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset stats  \n",
    "model.data.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select patient id \n",
    "pids = model.data.get_pids()                      # Get all patient ids, and use first patient as example                                         \n",
    "pid = pids[0]    \n",
    "\n",
    "# Print patient stats \n",
    "model.data.print_patient_stats(pid)\n",
    "\n",
    "# Print chunk data for up to 'max_chunks' chunks  \n",
    "max_chunks = 30\n",
    "print(model.data.get_formatted_chunks(pid, max_chunks)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query + Retrieval of Chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does the patient show signs of neurological issues like face numbness?\"\n",
    "\n",
    "retrieved = model.storage.search_index(pid, query)\n",
    "\n",
    "model.storage.print_retrieved_chunks(pid, retrieved)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer = model.generator.generate_response_from_chunks(query, retrieved)\n",
    "#print(\"== RESPONSE:==\")\n",
    "#print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
